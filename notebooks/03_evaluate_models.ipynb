{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8bacbc3",
   "metadata": {},
   "source": [
    "# 03 — Evaluate Models (Base & Zero-Day)\n",
    "\n",
    "This notebook evaluates all trained models on **validation** and **test** splits for both scenarios:\n",
    "\n",
    "- **Base scenario** — all classes included in training/validation.  \n",
    "- **Zero-Day scenario** — `Bot`, `Web Attack - Brute Force`, and `Infiltration` excluded from train/val, appear only in test.  \n",
    "\n",
    "### Evaluation procedure\n",
    "- Load models and metadata from `models/`.  \n",
    "- Rebuild preprocessing (imputer, scaler, PCA) where needed.  \n",
    "- Re-implement ET-SSL scoring from saved encoder + centroids.  \n",
    "- Compute **macro metrics**: confusion matrix, precision, recall, F1-score, ROC-AUC, PR-AUC.  \n",
    "- Measure **inference times**.  \n",
    "\n",
    "### Outputs\n",
    "- **Consolidated metrics**:  \n",
    "  - `results/metrics_summary.csv`  \n",
    "  - `results/metrics_summary.json`  \n",
    "- **Detailed exports**: full confusion-matrix stats (`metrics_full.csv`, LaTeX table),  \n",
    "- **Plots**: ROC and PR curves, confusion matrices, Macro-F1 barplots, zero-day subset results.  \n",
    "\n",
    "This ensures all three models are directly comparable across the same splits and metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8560ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Imports & configuration\n",
    "\n",
    "import os, json, time, math\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, precision_recall_fscore_support,\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve, roc_curve\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "ROOT = Path(\".\").resolve()\n",
    "SPLITS_DIR = ROOT / \"data\" / \"splits\"\n",
    "MODELS_DIR = ROOT / \"models\"\n",
    "RESULTS_DIR = ROOT / \"results\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LABEL_COL = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08132101-f302-479e-acac-cf21b522f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Figure & results helpers ====\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "RESULTS_DIR = Path(RESULTS_DIR) if \"RESULTS_DIR\" in globals() else Path(\"./results\")\n",
    "FIG_DIR     = RESULTS_DIR / \"figures\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig, name: str, dpi: int = 300):\n",
    "    p = FIG_DIR / f\"{name}.png\"\n",
    "    fig.savefig(p, dpi=dpi, bbox_inches=\"tight\")\n",
    "    print(f\"[saved] {p}\")\n",
    "\n",
    "def save_current_fig(name: str, dpi: int = 300):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.gcf()\n",
    "    save_fig(fig, name, dpi=dpi)\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_text(lines: str, name: str):\n",
    "    p = RESULTS_DIR / f\"{name}.txt\"\n",
    "    with open(p, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(lines)\n",
    "    print(f\"[saved] {p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840db25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Utilities: loader, metrics, CorrelatedGroupsPCA (for RF/IF)\n",
    "\n",
    "def load_split(approach: str, scenario: str, split: str) -> pd.DataFrame:\n",
    "    p = SPLITS_DIR / approach / scenario / f\"{split}.parquet\"\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(p)\n",
    "    return pd.read_parquet(p)\n",
    "\n",
    "def features_and_labels(df: pd.DataFrame) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    X = df.drop(columns=[LABEL_COL, \"Label\"], errors=\"ignore\")\n",
    "    y = df[LABEL_COL].values.astype(np.int64)\n",
    "    return X, y\n",
    "\n",
    "def compute_macro_metrics(y_true: np.ndarray, y_pred: np.ndarray, scores: np.ndarray=None) -> Dict[str, Any]:\n",
    "    pre, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    out = {\"macro_precision\": float(pre), \"macro_recall\": float(rec), \"macro_f1\": float(f1), \"accuracy\": float(acc)}\n",
    "    if scores is not None:\n",
    "        try:\n",
    "            out[\"roc_auc\"] = float(roc_auc_score(y_true, scores))\n",
    "        except Exception:\n",
    "            out[\"roc_auc\"] = None\n",
    "        try:\n",
    "            out[\"pr_auc\"] = float(average_precision_score(y_true, scores))\n",
    "        except Exception:\n",
    "            out[\"pr_auc\"] = None\n",
    "    return out\n",
    "\n",
    "class CorrelatedGroupsPCA:\n",
    "    def __init__(self, rho: float = 0.95, var_keep: float = 0.99):\n",
    "        self.rho = float(rho)\n",
    "        self.var_keep = float(var_keep)\n",
    "        self.groups_ = None\n",
    "        self.columns_ = None\n",
    "        self.pca_models_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        from sklearn.decomposition import PCA\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X_df = pd.DataFrame(X, columns=[f\"f{i}\" for i in range(X.shape[1])])\n",
    "        else:\n",
    "            X_df = X.copy()\n",
    "        self.columns_ = list(X_df.columns)\n",
    "        corr = X_df.corr(numeric_only=True).fillna(0.0).values\n",
    "        n = corr.shape[0]\n",
    "        visited = np.zeros(n, dtype=bool)\n",
    "        groups = []\n",
    "        for i in range(n):\n",
    "            if visited[i]: continue\n",
    "            g = [i]\n",
    "            visited[i] = True\n",
    "            for j in range(i+1, n):\n",
    "                if visited[j]: continue\n",
    "                if abs(corr[i, j]) >= self.rho:\n",
    "                    g.append(j); visited[j] = True\n",
    "            groups.append(sorted(g))\n",
    "        self.pca_models_ = []\n",
    "        for g in groups:\n",
    "            if len(g) == 1:\n",
    "                self.pca_models_.append((\"pass\", g, None))\n",
    "            else:\n",
    "                from sklearn.decomposition import PCA\n",
    "                pca = PCA(n_components=None, svd_solver=\"full\", random_state=SEED).fit(X_df.iloc[:, g])\n",
    "                csum = np.cumsum(pca.explained_variance_ratio_)\n",
    "                k = int(np.searchsorted(csum, self.var_keep) + 1)\n",
    "                k = max(1, min(k, len(g)))\n",
    "                pca_k = PCA(n_components=k, svd_solver=\"full\", random_state=SEED).fit(X_df.iloc[:, g])\n",
    "                self.pca_models_.append((\"pca\", g, pca_k))\n",
    "        self.groups_ = groups\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X_df = pd.DataFrame(X, columns=self.columns_)\n",
    "        else:\n",
    "            X_df = X.copy()\n",
    "        outs = []\n",
    "        for kind, g, model in self.pca_models_:\n",
    "            if kind == \"pass\":\n",
    "                outs.append(X_df.iloc[:, g].values)\n",
    "            else:\n",
    "                outs.append(model.transform(X_df.iloc[:, g]))\n",
    "        return np.concatenate(outs, axis=1)\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1a29cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## RF & IF evaluation helpers\n",
    "\n",
    "def eval_rf_or_if(model_path: Path, split_df: pd.DataFrame, use_prob: bool=True):\n",
    "    model = joblib.load(model_path)  # Pipeline(var0,impute,scaler,cgpca,estimator)\n",
    "    X, y = features_and_labels(split_df)\n",
    "    t0 = time.time()\n",
    "    if use_prob and hasattr(model, \"predict_proba\"):\n",
    "        scores = model.predict_proba(X)[:, 1]\n",
    "    else:\n",
    "        # IsolationForest: negative score_samples means more anomalous, but\n",
    "        # in training we saved a Pipeline; here we try both ways if needed\n",
    "        try:\n",
    "            scores = -model[-1].score_samples(model[:-1].transform(X))\n",
    "        except Exception:\n",
    "            # fallback to decision_function (shifted)\n",
    "            scores = -model[-1].decision_function(model[:-1].transform(X))\n",
    "    infer_s = time.time() - t0\n",
    "    return y, scores, infer_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab79878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## ET-SSL evaluation helpers (rebuild encoder + preprocessors)\n",
    "\n",
    "def load_etssl_meta(scenario: str):\n",
    "    with open(MODELS_DIR / f\"etssl_{scenario}_meta.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "class EncoderV2(nn.Module):\n",
    "    \"\"\"V2: 512→256→emb mit BN/Dropout, proj: BN→ReLU→Linear\"\"\"\n",
    "    def __init__(self, d, emb=64, proj=128, p_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.back = nn.Sequential(\n",
    "            nn.Linear(d, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(p_drop),\n",
    "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(p_drop),\n",
    "            nn.Linear(256, emb)\n",
    "        )\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.BatchNorm1d(emb), nn.ReLU(),\n",
    "            nn.Linear(emb, proj)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        h = self.back(x)\n",
    "        z = self.proj(h)\n",
    "        return z, h\n",
    "\n",
    "def rebuild_imputer_scaler(meta, n_features: int):\n",
    "    imp = SimpleImputer(strategy=\"median\")\n",
    "    stats = np.array(meta[\"imputer_statistics_\"], dtype=float)\n",
    "    if stats.shape[0] != n_features:\n",
    "        if stats.shape[0] > n_features:\n",
    "            stats = stats[:n_features]\n",
    "        else:\n",
    "            stats = np.pad(stats, (0, n_features - stats.shape[0]), constant_values=np.nan)\n",
    "    imp.statistics_ = stats\n",
    "    imp.n_features_in_ = int(n_features)\n",
    "    imp._fit_dtype = np.dtype(\"float64\")\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    sc.min_   = np.array(meta[\"scaler_min_\"],   dtype=float) if meta[\"scaler_min_\"]   is not None else np.zeros(n_features)\n",
    "    sc.scale_ = np.array(meta[\"scaler_scale_\"], dtype=float) if meta[\"scaler_scale_\"] is not None else np.ones(n_features)\n",
    "    sc.data_min_      = np.zeros(n_features)\n",
    "    sc.data_max_      = np.ones(n_features)\n",
    "    sc.data_range_    = np.ones(n_features)\n",
    "    sc.n_features_in_ = int(n_features)\n",
    "    sc.n_samples_seen_ = np.full(n_features, 1, dtype=np.int64)\n",
    "    return imp, sc\n",
    "\n",
    "\n",
    "\n",
    "def etssl_scores_for_df(scenario: str, split_df: pd.DataFrame):\n",
    "    # --- Meta & Weights ---\n",
    "    with open(MODELS_DIR / f\"etssl_{scenario}_meta.json\", \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    state = torch.load(MODELS_DIR / f\"etssl_{scenario}_encoder.pt\", map_location=\"cpu\")\n",
    "\n",
    "    # --- Features / Labels ---\n",
    "    X = split_df.drop(columns=[LABEL_COL, \"Label\"], errors=\"ignore\")\n",
    "    y = split_df[LABEL_COL].to_numpy().astype(np.int64)\n",
    "    d = X.shape[1]\n",
    "\n",
    "    # --- Imputer/Scaler ---\n",
    "    imp, sc = rebuild_imputer_scaler(meta, n_features=d)\n",
    "\n",
    "    # --- Encoder V2 ---\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    enc = EncoderV2(d, emb=int(meta[\"emb_dim\"]), proj=int(meta[\"proj_dim\"])).to(device)\n",
    "    enc.load_state_dict(state, strict=True)\n",
    "    enc.eval()\n",
    "\n",
    "    # --- Transform + encode ---\n",
    "    X_np = X.to_numpy(dtype=float, copy=False)\n",
    "    Xp = sc.transform(imp.transform(X_np)).astype(np.float32, copy=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Z = []\n",
    "        for i in range(0, len(Xp), 4096):\n",
    "            xb = torch.from_numpy(Xp[i:i+4096]).to(device)\n",
    "            _, h = enc(xb)\n",
    "            Z.append(nn.functional.normalize(h, dim=1).cpu().numpy())\n",
    "        Z = np.vstack(Z)\n",
    "\n",
    "    # --- Scores ---\n",
    "    mu_norm = np.array(meta[\"mu_norm\"], dtype=float)\n",
    "    mu_anom = np.array(meta[\"mu_anom\"], dtype=float)\n",
    "    kappa   = float(meta[\"kappa\"])\n",
    "\n",
    "    dn = ((Z - mu_norm)**2).sum(1)\n",
    "    da = ((Z - mu_anom)**2).sum(1)\n",
    "    scores = dn - kappa * da\n",
    "    return y, scores, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7788e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Scenario: BASE\n",
      "==============================\n",
      "\n",
      "==============================\n",
      "Scenario: ZERODAY\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>scenario</th>\n",
       "      <th>split</th>\n",
       "      <th>infer_s</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>etssl</td>\n",
       "      <td>base</td>\n",
       "      <td>test</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847067</td>\n",
       "      <td>0.878041</td>\n",
       "      <td>0.861127</td>\n",
       "      <td>0.908212</td>\n",
       "      <td>0.947739</td>\n",
       "      <td>0.821380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>etssl</td>\n",
       "      <td>base</td>\n",
       "      <td>val</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.846831</td>\n",
       "      <td>0.877339</td>\n",
       "      <td>0.860704</td>\n",
       "      <td>0.908174</td>\n",
       "      <td>0.947572</td>\n",
       "      <td>0.821606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if</td>\n",
       "      <td>base</td>\n",
       "      <td>test</td>\n",
       "      <td>1.646487</td>\n",
       "      <td>0.744153</td>\n",
       "      <td>0.685819</td>\n",
       "      <td>0.706915</td>\n",
       "      <td>0.835908</td>\n",
       "      <td>0.729613</td>\n",
       "      <td>0.473934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if</td>\n",
       "      <td>base</td>\n",
       "      <td>val</td>\n",
       "      <td>1.627240</td>\n",
       "      <td>0.742872</td>\n",
       "      <td>0.685400</td>\n",
       "      <td>0.706265</td>\n",
       "      <td>0.835679</td>\n",
       "      <td>0.729674</td>\n",
       "      <td>0.472114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>base</td>\n",
       "      <td>test</td>\n",
       "      <td>1.064283</td>\n",
       "      <td>0.990767</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.994175</td>\n",
       "      <td>0.996292</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.999870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf</td>\n",
       "      <td>base</td>\n",
       "      <td>val</td>\n",
       "      <td>1.084327</td>\n",
       "      <td>0.990567</td>\n",
       "      <td>0.997642</td>\n",
       "      <td>0.994057</td>\n",
       "      <td>0.996223</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>etssl</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>test</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.837887</td>\n",
       "      <td>0.867065</td>\n",
       "      <td>0.851165</td>\n",
       "      <td>0.901769</td>\n",
       "      <td>0.924782</td>\n",
       "      <td>0.652962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>etssl</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>val</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.837795</td>\n",
       "      <td>0.868488</td>\n",
       "      <td>0.851700</td>\n",
       "      <td>0.902357</td>\n",
       "      <td>0.925336</td>\n",
       "      <td>0.650409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>if</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>test</td>\n",
       "      <td>1.612712</td>\n",
       "      <td>0.744153</td>\n",
       "      <td>0.685819</td>\n",
       "      <td>0.706915</td>\n",
       "      <td>0.835908</td>\n",
       "      <td>0.729613</td>\n",
       "      <td>0.473934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>if</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>val</td>\n",
       "      <td>1.615562</td>\n",
       "      <td>0.742872</td>\n",
       "      <td>0.685400</td>\n",
       "      <td>0.706265</td>\n",
       "      <td>0.835679</td>\n",
       "      <td>0.729674</td>\n",
       "      <td>0.472114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rf</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>test</td>\n",
       "      <td>1.199695</td>\n",
       "      <td>0.990237</td>\n",
       "      <td>0.996036</td>\n",
       "      <td>0.993104</td>\n",
       "      <td>0.995615</td>\n",
       "      <td>0.998901</td>\n",
       "      <td>0.998231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rf</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>val</td>\n",
       "      <td>1.012854</td>\n",
       "      <td>0.988837</td>\n",
       "      <td>0.997208</td>\n",
       "      <td>0.992956</td>\n",
       "      <td>0.995529</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model scenario split   infer_s  macro_precision  macro_recall  macro_f1  \\\n",
       "0   etssl     base  test  0.000000         0.847067      0.878041  0.861127   \n",
       "1   etssl     base   val  0.000000         0.846831      0.877339  0.860704   \n",
       "2      if     base  test  1.646487         0.744153      0.685819  0.706915   \n",
       "3      if     base   val  1.627240         0.742872      0.685400  0.706265   \n",
       "4      rf     base  test  1.064283         0.990767      0.997674  0.994175   \n",
       "5      rf     base   val  1.084327         0.990567      0.997642  0.994057   \n",
       "6   etssl  zeroday  test  0.000000         0.837887      0.867065  0.851165   \n",
       "7   etssl  zeroday   val  0.000000         0.837795      0.868488  0.851700   \n",
       "8      if  zeroday  test  1.612712         0.744153      0.685819  0.706915   \n",
       "9      if  zeroday   val  1.615562         0.742872      0.685400  0.706265   \n",
       "10     rf  zeroday  test  1.199695         0.990237      0.996036  0.993104   \n",
       "11     rf  zeroday   val  1.012854         0.988837      0.997208  0.992956   \n",
       "\n",
       "    accuracy   roc_auc    pr_auc  \n",
       "0   0.908212  0.947739  0.821380  \n",
       "1   0.908174  0.947572  0.821606  \n",
       "2   0.835908  0.729613  0.473934  \n",
       "3   0.835679  0.729674  0.472114  \n",
       "4   0.996292  0.999970  0.999870  \n",
       "5   0.996223  0.999966  0.999876  \n",
       "6   0.901769  0.924782  0.652962  \n",
       "7   0.902357  0.925336  0.650409  \n",
       "8   0.835908  0.729613  0.473934  \n",
       "9   0.835679  0.729674  0.472114  \n",
       "10  0.995615  0.998901  0.998231  \n",
       "11  0.995529  0.999950  0.999832  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Run evaluation for both scenarios and all models\n",
    "\n",
    "rows = []\n",
    "for scenario in [\"base\", \"zeroday\"]:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"Scenario: {scenario.upper()}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    for split in [\"val\", \"test\"]:\n",
    "        # RF\n",
    "        y, scores, secs = eval_rf_or_if(MODELS_DIR / f\"rf_{scenario}.joblib\", load_split(\"rf\", scenario, split), use_prob=True)\n",
    "        # Load threshold from meta\n",
    "        with open(MODELS_DIR / f\"rf_{scenario}_meta.json\", \"r\") as f:\n",
    "            thr = json.load(f)[\"threshold\"]\n",
    "        yhat = (scores >= thr).astype(int)\n",
    "        m = compute_macro_metrics(y, yhat, scores)\n",
    "        rows.append({\"model\":\"rf\",\"scenario\":scenario,\"split\":split,\"infer_s\":secs, **m})\n",
    "\n",
    "        # IF\n",
    "        y, scores, secs = eval_rf_or_if(MODELS_DIR / f\"if_{scenario}.joblib\", load_split(\"if\", scenario, split), use_prob=False)\n",
    "        with open(MODELS_DIR / f\"if_{scenario}_meta.json\", \"r\") as f:\n",
    "            thr = json.load(f)[\"threshold\"]\n",
    "        yhat = (scores >= thr).astype(int)\n",
    "        m = compute_macro_metrics(y, yhat, scores)\n",
    "        rows.append({\"model\":\"if\",\"scenario\":scenario,\"split\":split,\"infer_s\":secs, **m})\n",
    "\n",
    "        # ETSSL\n",
    "        y, scores, secs = etssl_scores_for_df(scenario, load_split(\"etssl\", scenario, split))\n",
    "        with open(MODELS_DIR / f\"etssl_{scenario}_meta.json\", \"r\") as f:\n",
    "            meta = json.load(f)\n",
    "            thr = meta[\"theta\"]\n",
    "        yhat = (scores >= thr).astype(int)\n",
    "        m = compute_macro_metrics(y, yhat, scores)\n",
    "        rows.append({\"model\":\"etssl\",\"scenario\":scenario,\"split\":split,\"infer_s\":secs, **m})\n",
    "\n",
    "df_res = pd.DataFrame(rows)\n",
    "df_res = df_res.sort_values([\"scenario\",\"model\",\"split\"]).reset_index(drop=True)\n",
    "df_res.to_csv(RESULTS_DIR / \"metrics_summary.csv\", index=False)\n",
    "with open(RESULTS_DIR / \"metrics_summary.json\", \"w\") as f:\n",
    "    json.dump(df_res.to_dict(orient=\"records\"), f, indent=2)\n",
    "\n",
    "df_res.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7e723-ee46-4d96-9e03-8573f9f66831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scenario: base ===\n",
      "[RF/base] F1=0.9942 AUC=1.0000 AP=0.9999 test_s=1.06\n",
      "[IF/base] F1=0.7069 AUC=0.7296 AP=0.4739 test_s=1.65\n",
      "[ETSSL/base] F1=0.8611 AUC=0.9477 AP=0.8214 test_s=0.00\n",
      "\n",
      "=== Scenario: zeroday ===\n",
      "[RF/zeroday] F1=0.9931 AUC=0.9989 AP=0.9982 test_s=1.20\n",
      "[IF/zeroday] F1=0.7069 AUC=0.7296 AP=0.4739 test_s=1.61\n",
      "[ETSSL/zeroday] F1=0.8512 AUC=0.9248 AP=0.6530 test_s=0.00\n",
      "[saved] /home/user/project/results/summary_test_metrics.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>scenario</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_ap</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>ACC</th>\n",
       "      <th>thr</th>\n",
       "      <th>test_time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>base</td>\n",
       "      <td>0.994175</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>83454</td>\n",
       "      <td>339155</td>\n",
       "      <td>1569</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.995395</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.996292</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>1.064283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if</td>\n",
       "      <td>base</td>\n",
       "      <td>0.706915</td>\n",
       "      <td>0.729613</td>\n",
       "      <td>0.473934</td>\n",
       "      <td>36584</td>\n",
       "      <td>317993</td>\n",
       "      <td>22731</td>\n",
       "      <td>46874</td>\n",
       "      <td>0.438352</td>\n",
       "      <td>0.933286</td>\n",
       "      <td>0.066714</td>\n",
       "      <td>0.561648</td>\n",
       "      <td>0.835908</td>\n",
       "      <td>0.503404</td>\n",
       "      <td>1.646487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>etssl</td>\n",
       "      <td>base</td>\n",
       "      <td>0.861127</td>\n",
       "      <td>0.947739</td>\n",
       "      <td>0.821380</td>\n",
       "      <td>69128</td>\n",
       "      <td>316119</td>\n",
       "      <td>24605</td>\n",
       "      <td>14330</td>\n",
       "      <td>0.828297</td>\n",
       "      <td>0.927786</td>\n",
       "      <td>0.072214</td>\n",
       "      <td>0.171703</td>\n",
       "      <td>0.908212</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>0.993104</td>\n",
       "      <td>0.998901</td>\n",
       "      <td>0.998231</td>\n",
       "      <td>83185</td>\n",
       "      <td>339137</td>\n",
       "      <td>1587</td>\n",
       "      <td>273</td>\n",
       "      <td>0.996729</td>\n",
       "      <td>0.995342</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.995615</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>1.199695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>0.706915</td>\n",
       "      <td>0.729613</td>\n",
       "      <td>0.473934</td>\n",
       "      <td>36584</td>\n",
       "      <td>317993</td>\n",
       "      <td>22731</td>\n",
       "      <td>46874</td>\n",
       "      <td>0.438352</td>\n",
       "      <td>0.933286</td>\n",
       "      <td>0.066714</td>\n",
       "      <td>0.561648</td>\n",
       "      <td>0.835908</td>\n",
       "      <td>0.503404</td>\n",
       "      <td>1.612712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>etssl</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>0.851165</td>\n",
       "      <td>0.924782</td>\n",
       "      <td>0.652962</td>\n",
       "      <td>67588</td>\n",
       "      <td>314926</td>\n",
       "      <td>25798</td>\n",
       "      <td>15870</td>\n",
       "      <td>0.809844</td>\n",
       "      <td>0.924285</td>\n",
       "      <td>0.075715</td>\n",
       "      <td>0.190156</td>\n",
       "      <td>0.901769</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  approach scenario  macro_f1   roc_auc     pr_ap     TP      TN     FP  \\\n",
       "0       rf     base  0.994175  0.999970  0.999870  83454  339155   1569   \n",
       "1       if     base  0.706915  0.729613  0.473934  36584  317993  22731   \n",
       "2    etssl     base  0.861127  0.947739  0.821380  69128  316119  24605   \n",
       "3       rf  zeroday  0.993104  0.998901  0.998231  83185  339137   1587   \n",
       "4       if  zeroday  0.706915  0.729613  0.473934  36584  317993  22731   \n",
       "5    etssl  zeroday  0.851165  0.924782  0.652962  67588  314926  25798   \n",
       "\n",
       "      FN       TPR       TNR       FPR       FNR       ACC       thr  \\\n",
       "0      4  0.999952  0.995395  0.004605  0.000048  0.996292  0.009451   \n",
       "1  46874  0.438352  0.933286  0.066714  0.561648  0.835908  0.503404   \n",
       "2  14330  0.828297  0.927786  0.072214  0.171703  0.908212  0.000822   \n",
       "3    273  0.996729  0.995342  0.004658  0.003271  0.995615  0.003259   \n",
       "4  46874  0.438352  0.933286  0.066714  0.561648  0.835908  0.503404   \n",
       "5  15870  0.809844  0.924285  0.075715  0.190156  0.901769  0.000218   \n",
       "\n",
       "   test_time_sec  \n",
       "0       1.064283  \n",
       "1       1.646487  \n",
       "2       0.000000  \n",
       "3       1.199695  \n",
       "4       1.612712  \n",
       "5       0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] /home/user/project/results/metrics_latex.tex\n",
      "[saved] /home/user/project/results/metrics_full.csv\n",
      "[saved] /home/user/project/results/figures/roc_base.png\n",
      "[saved] /home/user/project/results/figures/pr_base.png\n",
      "[saved] /home/user/project/results/figures/roc_zeroday.png\n",
      "[saved] /home/user/project/results/figures/pr_zeroday.png\n",
      "[saved] /home/user/project/results/figures/macro_f1_by_approach_scenario.png\n",
      "[saved] /home/user/project/results/figures/cm_rf_base.png\n",
      "[saved] /home/user/project/results/figures/cm_if_base.png\n",
      "[saved] /home/user/project/results/figures/cm_etssl_base.png\n",
      "[saved] /home/user/project/results/figures/cm_rf_zeroday.png\n",
      "[saved] /home/user/project/results/figures/cm_if_zeroday.png\n",
      "[saved] /home/user/project/results/figures/cm_etssl_zeroday.png\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Summaries, Tables & Plots  (auto-save)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# names\n",
    "MODEL_NAME = {\"rf\": \"Random Forest\", \"if\": \"Isolation Forest\", \"etssl\": \"ET-SSL\"}\n",
    "SCEN_NAME  = {\"base\": \"Base\", \"zeroday\": \"Zero-Day\"}\n",
    "\n",
    "# --- Pretty-print summary + save as text ---\n",
    "summary_lines = []\n",
    "for scenario in [\"base\", \"zeroday\"]:\n",
    "    header = f\"\\n=== Scenario: {scenario} ===\"\n",
    "    print(header); summary_lines.append(header)\n",
    "    for model in [\"rf\", \"if\", \"etssl\"]:\n",
    "        r = df_res.query(\"scenario == @scenario and split == 'test' and model == @model\").iloc[0]\n",
    "        line = (f\"[{model.upper()}/{scenario}] \"\n",
    "                f\"F1={r['macro_f1']:.4f} AUC={r['roc_auc']:.4f} AP={r['pr_auc']:.4f} \"\n",
    "                f\"test_s={r['infer_s']:.2f}\")\n",
    "        print(line); summary_lines.append(line)\n",
    "save_text(\"\\n\".join(summary_lines).strip(), \"summary_test_metrics\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Compute detailed confusion matrix stats for all 6\n",
    "# ---------------------------------------------------\n",
    "details = []\n",
    "for scenario in [\"base\",\"zeroday\"]:\n",
    "    for model in [\"rf\",\"if\",\"etssl\"]:\n",
    "        split_df = load_split(model, scenario, \"test\")\n",
    "        X, y = features_and_labels(split_df)\n",
    "\n",
    "        if model in [\"rf\",\"if\"]:\n",
    "            y, scores, _ = eval_rf_or_if(MODELS_DIR/f\"{model}_{scenario}.joblib\", split_df, use_prob=(model==\"rf\"))\n",
    "            with open(MODELS_DIR/f\"{model}_{scenario}_meta.json\") as f: thr = json.load(f)[\"threshold\"]\n",
    "        else:\n",
    "            y, scores, _ = etssl_scores_for_df(scenario, split_df)\n",
    "            with open(MODELS_DIR/f\"etssl_{scenario}_meta.json\") as f: thr = json.load(f)[\"theta\"]\n",
    "\n",
    "        yhat = (scores >= thr).astype(int)\n",
    "        cm = confusion_matrix(y, yhat, labels=[0,1])\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        tpr = tp/(tp+fn+1e-12)\n",
    "        tnr = tn/(tn+fp+1e-12)\n",
    "        fpr = fp/(fp+tn+1e-12)\n",
    "        fnr = fn/(fn+tp+1e-12)\n",
    "        acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "        row = dict(approach=model, scenario=scenario,\n",
    "                   macro_f1=float(precision_recall_fscore_support(y,yhat,average=\"macro\")[2]),\n",
    "                   roc_auc=float(roc_auc_score(y, scores)),\n",
    "                   pr_ap=float(average_precision_score(y, scores)),\n",
    "                   TP=tp, TN=tn, FP=fp, FN=fn,\n",
    "                   TPR=tpr, TNR=tnr, FPR=fpr, FNR=fnr,\n",
    "                   ACC=acc, thr=thr, test_time_sec=df_res.query(\"scenario==@scenario and model==@model and split=='test'\").iloc[0][\"infer_s\"])\n",
    "        details.append(row)\n",
    "\n",
    "df_full = pd.DataFrame(details)\n",
    "display(df_full)\n",
    "\n",
    "# Save table variants\n",
    "latex_path = RESULTS_DIR / \"metrics_latex.tex\"\n",
    "csv_path   = RESULTS_DIR / \"metrics_full.csv\"\n",
    "with open(latex_path,\"w\") as f:\n",
    "    f.write(df_full.to_latex(index=False, float_format=\"%.4f\"))\n",
    "df_full.to_csv(csv_path, index=False)\n",
    "print(f\"[saved] {latex_path}\")\n",
    "print(f\"[saved] {csv_path}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# ROC and PR curves (saved)\n",
    "# ---------------------------------------------------\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "def plot_curves(kind=\"roc\", scenario=\"base\"):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for model in [\"rf\",\"if\",\"etssl\"]:\n",
    "        split_df = load_split(model, scenario, \"test\")\n",
    "        if model in [\"rf\",\"if\"]:\n",
    "            y, scores, _ = eval_rf_or_if(MODELS_DIR/f\"{model}_{scenario}.joblib\", split_df, use_prob=(model==\"rf\"))\n",
    "        else:\n",
    "            y, scores, _ = etssl_scores_for_df(scenario, split_df)\n",
    "\n",
    "        if kind==\"roc\":\n",
    "            fpr, tpr, _ = roc_curve(y, scores)\n",
    "            plt.plot(fpr, tpr, label=MODEL_NAME[model])  \n",
    "            plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(f\"ROC — {SCEN_NAME[scenario]}\")\n",
    "            fname = f\"roc_{scenario}\"\n",
    "        else:\n",
    "            prec, rec, _ = precision_recall_curve(y, scores)\n",
    "            plt.plot(rec, prec, label=MODEL_NAME[model])\n",
    "            plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "            plt.title(f\"PR — {SCEN_NAME[scenario]}\")\n",
    "            fname = f\"pr_{scenario}\"\n",
    "    plt.legend(); plt.grid(True)\n",
    "    save_current_fig(fname)\n",
    "\n",
    "for s in [\"base\",\"zeroday\"]:\n",
    "    plot_curves(\"roc\", s)\n",
    "    plot_curves(\"pr\",  s)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Macro-F1 barplots (saved)\n",
    "# ---------------------------------------------------\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.barplot(data=df_full, x=\"approach\", y=\"macro_f1\", hue=\"scenario\")\n",
    "plt.title(\"Macro-F1 by Approach & Scenario\")\n",
    "save_current_fig(\"macro_f1_by_approach_scenario\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Confusion matrices (saved)\n",
    "# ---------------------------------------------------\n",
    "for s in [\"base\",\"zeroday\"]:\n",
    "    for m in [\"rf\",\"if\",\"etssl\"]:\n",
    "        split_df = load_split(m, s, \"test\")\n",
    "        if m in [\"rf\",\"if\"]:\n",
    "            y, scores, _ = eval_rf_or_if(MODELS_DIR/f\"{m}_{s}.joblib\", split_df, use_prob=(m==\"rf\"))\n",
    "            with open(MODELS_DIR/f\"{m}_{s}_meta.json\") as f: thr = json.load(f)[\"threshold\"]\n",
    "        else:\n",
    "            y, scores, _ = etssl_scores_for_df(s, split_df)\n",
    "            with open(MODELS_DIR/f\"etssl_{s}_meta.json\") as f: thr = json.load(f)[\"theta\"]\n",
    "\n",
    "        yhat = (scores >= thr).astype(int)\n",
    "        cm = confusion_matrix(y, yhat, labels=[0,1])\n",
    "        disp = ConfusionMatrixDisplay(cm, display_labels=[\"Benign\",\"Attack\"])\n",
    "        disp.plot(values_format=\"d\")\n",
    "        plt.title(f\"Confusion Matrix — {MODEL_NAME[m]} / {SCEN_NAME[s]}\")\n",
    "        save_current_fig(f\"cm_{m}_{s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27990667-f612-45db-818c-313d1d23860c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-day labels inferred (3): ['Bot', 'Infiltration', 'Web Attack - Brute Force']\n",
      "[saved] /home/user/project/results/zero_day_labels.txt\n",
      "\n",
      "==============================\n",
      "Zero-Day Confusion Matrices — Base\n",
      "==============================\n",
      "[RF/base] TP=509  TN=0  FP=0  FN=4  |  N=513\n",
      "[saved] /home/user/project/results/figures/cm_zeroday_only_rf_base.png\n",
      "[IF/base] TP=24  TN=0  FP=0  FN=489  |  N=513\n",
      "[saved] /home/user/project/results/figures/cm_zeroday_only_if_base.png\n",
      "[ETSSL/base] TP=206  TN=0  FP=0  FN=307  |  N=513\n",
      "[saved] /home/user/project/results/figures/cm_zeroday_only_etssl_base.png\n",
      "\n",
      "==============================\n",
      "Zero-Day Confusion Matrices — Zero-Day\n",
      "==============================\n",
      "[RF/zeroday] TP=240  TN=0  FP=0  FN=273  |  N=513\n",
      "[saved] /home/user/project/results/figures/cm_zeroday_only_rf_zeroday.png\n",
      "[IF/zeroday] TP=24  TN=0  FP=0  FN=489  |  N=513\n",
      "[saved] /home/user/project/results/figures/cm_zeroday_only_if_zeroday.png\n",
      "[ETSSL/zeroday] TP=195  TN=0  FP=0  FN=318  |  N=513\n",
      "[saved] /home/user/project/results/figures/cm_zeroday_only_etssl_zeroday.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>scenario</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>base</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if</td>\n",
       "      <td>base</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>489</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>etssl</td>\n",
       "      <td>base</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>489</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>etssl</td>\n",
       "      <td>zeroday</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  approach scenario   TP  TN  FP   FN    N\n",
       "0       rf     base  509   0   0    4  513\n",
       "1       if     base   24   0   0  489  513\n",
       "2    etssl     base  206   0   0  307  513\n",
       "3       rf  zeroday  240   0   0  273  513\n",
       "4       if  zeroday   24   0   0  489  513\n",
       "5    etssl  zeroday  195   0   0  318  513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] /home/user/project/results/zero_day_confusion_matrices.tex\n",
      "[saved] /home/user/project/results/zero_day_confusion_matrices.csv\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Zero-Day Only — Confusion Matrices (all models, both scenarios)  (auto-save)\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "MODEL_NAME = {\"rf\": \"Random Forest\", \"if\": \"Isolation Forest\", \"etssl\": \"ET-SSL\"}\n",
    "SCEN_NAME  = {\"base\": \"Base\", \"zeroday\": \"Zero-Day\"}\n",
    "\n",
    "def infer_zero_day_labels() -> set:\n",
    "    \"\"\"\n",
    "    Infer zero-day labels as attack labels present in zeroday/test but absent in zeroday/train.\n",
    "    Uses RF splits (identical label space across approaches).\n",
    "    \"\"\"\n",
    "    df_train = load_split(\"rf\", \"zeroday\", \"train\")\n",
    "    df_test  = load_split(\"rf\", \"zeroday\", \"test\")\n",
    "\n",
    "    train_attacks = set(df_train.loc[df_train[LABEL_COL] == 1, \"Label\"].dropna().unique())\n",
    "    test_attacks  = set(df_test.loc[df_test[LABEL_COL]  == 1, \"Label\"].dropna().unique())\n",
    "    zero_day = sorted(list(test_attacks - train_attacks))\n",
    "    return set(zero_day)\n",
    "\n",
    "ZD_LABELS = infer_zero_day_labels()\n",
    "print(f\"Zero-day labels inferred ({len(ZD_LABELS)}): {sorted(ZD_LABELS)}\")\n",
    "save_text(\"Zero-day labels:\\n\" + \"\\n\".join(sorted(ZD_LABELS)), \"zero_day_labels\")\n",
    "\n",
    "def zero_day_subset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"Label\" not in df.columns:\n",
    "        raise ValueError(\"Column 'Label' (string labels) not found; needed to filter zero-day classes.\")\n",
    "    return df[df[\"Label\"].isin(ZD_LABELS)].copy()\n",
    "\n",
    "def cm_for_model_scenario_zero_day(model: str, scenario: str):\n",
    "    \"\"\"\n",
    "    Compute confusion matrix restricted to zero-day rows of the *test* split.\n",
    "    \"\"\"\n",
    "    df_test = load_split(model, scenario, \"test\")\n",
    "    df_zd   = zero_day_subset(df_test)\n",
    "    if df_zd.empty:\n",
    "        print(f\"[{model.upper()}/{scenario}] No zero-day rows in test split.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Scores & threshold\n",
    "    if model in [\"rf\", \"if\"]:\n",
    "        y, scores, _ = eval_rf_or_if(MODELS_DIR / f\"{model}_{scenario}.joblib\", df_zd, use_prob=(model==\"rf\"))\n",
    "        with open(MODELS_DIR / f\"{model}_{scenario}_meta.json\") as f:\n",
    "            thr = json.load(f)[\"threshold\"]\n",
    "    else:\n",
    "        y, scores, _ = etssl_scores_for_df(scenario, df_zd)\n",
    "        with open(MODELS_DIR / f\"etssl_{scenario}_meta.json\") as f:\n",
    "            thr = json.load(f)[\"theta\"]\n",
    "\n",
    "    yhat = (scores >= thr).astype(int)\n",
    "    cm = confusion_matrix(y, yhat, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return cm, (tn, fp, fn, tp), y, yhat\n",
    "\n",
    "# --- Print counts, plot, and save ---\n",
    "zd_rows = []\n",
    "for scenario in [\"base\", \"zeroday\"]:\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"Zero-Day Confusion Matrices — {SCEN_NAME[scenario]}\")\n",
    "    print(\"=\"*30)\n",
    "    for model in [\"rf\",\"if\",\"etssl\"]:\n",
    "        try:\n",
    "            cm, (tn, fp, fn, tp), y, yhat = cm_for_model_scenario_zero_day(model, scenario)\n",
    "            if cm is None:\n",
    "                continue\n",
    "            # Numeric dump\n",
    "            line = f\"[{model.upper()}/{scenario}] TP={tp}  TN={tn}  FP={fp}  FN={fn}  |  N={len(y)}\"\n",
    "            print(line)\n",
    "            zd_rows.append(dict(approach=model, scenario=scenario, TP=tp, TN=tn, FP=fp, FN=fn, N=len(y)))\n",
    "            # Plot & save CM\n",
    "            disp = ConfusionMatrixDisplay(cm, display_labels=[\"Benign\",\"Attack\"])\n",
    "            disp.plot(values_format=\"d\")\n",
    "            plt.title(f\"Zero-Day CM — {MODEL_NAME[model]} / {SCEN_NAME[scenario]}\")\n",
    "            save_current_fig(f\"cm_zeroday_only_{model}_{scenario}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] {model}/{scenario} failed on zero-day subset: {e}\")\n",
    "\n",
    "# Export LaTeX + CSV der Zero-Day CMs\n",
    "df_zd = pd.DataFrame(zd_rows)\n",
    "display(df_zd)\n",
    "zd_tex = RESULTS_DIR / \"zero_day_confusion_matrices.tex\"\n",
    "zd_csv = RESULTS_DIR / \"zero_day_confusion_matrices.csv\"\n",
    "with open(zd_tex, \"w\") as f:\n",
    "    f.write(df_zd.to_latex(index=False))\n",
    "df_zd.to_csv(zd_csv, index=False)\n",
    "print(f\"[saved] {zd_tex}\")\n",
    "print(f\"[saved] {zd_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
